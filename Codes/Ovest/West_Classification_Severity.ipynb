{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de143a0e-0edc-4f33-be4b-f855a41c844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davide\\anaconda3\\envs\\pyspark_env\\Lib\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import pyarrow\n",
    "from pyspark.sql import SQLContext\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "conf = pyspark.SparkConf()\\\n",
    "        .setAppName('spark_pipeline')\\\n",
    "        .setMaster('local')\\\n",
    "        .set('spark.driver.memory', '8g')\\\n",
    "        .set('spark.executor.memory', '8g')\\\n",
    "        .set('spark.executor.instances', 4)\\\n",
    "        .set('spark.executor.cores', 4)\\\n",
    "        .set('spark.driver.maxResultSize', '8g')\\\n",
    "        .set('spark.sql.shuffle.partitions', 100)\\\n",
    "        .set('spark.default.parallelism', 200)\\\n",
    "        .set('spark.sql.broadcastTimeout', 36000)\\\n",
    "        .set('spark.kryoserializer.buffer.max', '1024m')\\\n",
    "        .set('spark.sql.execution.arrow.enabled', 'false')\\\n",
    "        .set('spark.dynamicAllocation.enabled', \"False\")\\\n",
    "        .set('spark.port.maxRetries',30) \n",
    "sc = pyspark.SparkContext.getOrCreate(conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "sqlContext = SQLContext.getOrCreate(sc)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173471ea-f9b1-4d4d-9e3c-68535aea04d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder\n",
    "from pyspark.sql import SQLContext, SparkSession, Row\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler, StandardScaler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import when, count, isnull\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "#spark = SparkSession.Builder().appName('DDAM_Project_west').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693d7c3a-6f27-4d66-a2fe-009bb704df33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.options(inferSchema = True, delimiter = ',', header = True).csv('../../Datasets/West_Incidents_Cleaned.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf8eb3a-419e-4306-987c-a9a15f3d0566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df.drop('Wind_Chill_F','Pressure_in','_c0') #devo droppare queste colonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08d595c-f636-420f-951d-eddce4dbde85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Severity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start_Time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start_Lat</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start_Lng</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance_mi</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature_F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity_perc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visibility_mi</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind_Direction</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind_Speed_mph</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation_in</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amenity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bump</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crossing</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Give_Way</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junction</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No_Exit</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Railway</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roundabout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_the_week</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Working_Weekend</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_Condition</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "Severity               0\n",
       "Start_Time             0\n",
       "Start_Lat              0\n",
       "Start_Lng              0\n",
       "Distance_mi            0\n",
       "County                 0\n",
       "State                  0\n",
       "Temperature_F          0\n",
       "Humidity_perc          0\n",
       "Visibility_mi          0\n",
       "Wind_Direction         0\n",
       "Wind_Speed_mph         0\n",
       "Precipitation_in       0\n",
       "Amenity                0\n",
       "Bump                   0\n",
       "Crossing               0\n",
       "Give_Way               0\n",
       "Junction               0\n",
       "No_Exit                0\n",
       "Railway                0\n",
       "Roundabout             0\n",
       "Station                0\n",
       "Stop                   0\n",
       "Traffic_Calming        0\n",
       "Traffic_Signal         0\n",
       "month                  0\n",
       "day_of_the_week        0\n",
       "hour                   0\n",
       "season                 0\n",
       "Working_Weekend        0\n",
       "City                   0\n",
       "Astronomical_Twilight  0\n",
       "Weather_Condition      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking missing values\n",
    "from pyspark.sql.functions import when, count, isnull\n",
    "missing = df.select([count(when(isnull(c), c)).alias(c) for c in df.columns])\n",
    "missing.toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759074f-d338-46b8-aec7-17aec19e6f47",
   "metadata": {},
   "source": [
    "### Preparazione dei dati "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182357d1-4898-4cef-ac88-7941b9d9b6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# droppo colonne che non uso un fase di classificazione \n",
    "to_drop=['Start_Time','City','County','State','Wind_Direction','day_of_the_week','season']\n",
    "df_class=df.drop(*to_drop)\n",
    "#df_class.show()\n",
    "\n",
    "# da controllare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49682e42-b4ca-4194-9f43-5a9e89b67124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converto le colonne booleane in numeriche\n",
    "\n",
    "boolean_attr = ['Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal']\n",
    "for col_ in boolean_attr:\n",
    "    df_class = df_class.withColumn(col_, col(col_).cast(\"int\"))\n",
    "\n",
    "#df_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0b4257-c447-4f1f-93ba-ca7837c65b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import when, count, isnull\n",
    "#replace_astronomical_twilight= udf(lambda value: 0 if value == \"Day\" else 1, IntegerType())\n",
    "#replace_working_weekend = udf(lambda value: 0 if value == \"WorkingDay\" else 1, IntegerType())\n",
    "\n",
    "#df_class = df_class.withColumn(\"Astronomical_Twilight\", replace_astronomical_twilight(\"Astronomical_Twilight\"))\n",
    "#df_class = df_class.withColumn(\"Working_Weekend\", replace_working_weekend(\"Working_Weekend\"))\n",
    "df_class = df_class.withColumn(\"Astronomical_Twilight\", when(df_class[\"Astronomical_Twilight\"] == 'Day', 0).otherwise(1))\n",
    "df_class = df_class.withColumn(\"Working_Weekend\", when(df_class[\"Working_Weekend\"] == 'WorkingDay', 0).otherwise(1))\n",
    "\n",
    "\n",
    "#df_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d9488d-c7ea-4255-b524-7fa6652d8dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# faccio indexer su weather condition \n",
    "indexer = StringIndexer(inputCol=\"Weather_Condition\", outputCol=\"Weather_Condition_Indexed\")\n",
    "df_class = indexer.fit(df_class).transform(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f05add4-869c-4509-bc6a-088b1cad7952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# faccio il one hot encoding di Weather \n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "onehotencoder_vector = OneHotEncoder(inputCol=\"Weather_Condition_Indexed\", outputCol=\"Weather_Condition_1hot\")\n",
    "df_class = onehotencoder_vector.fit(df_class).transform(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766836fe-6075-4a20-8e65-0a3700cc9ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# droppo la vecchia colonna Weather\n",
    "df_class=df_class.drop('Weather_Condition')\n",
    "#df_class.show()\n",
    "\n",
    "df_class=df_class.drop('Weather_Condition_Indexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ed1e75-d754-41f1-87b3-64dc2dd812d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' labels = [\"0\", \"1\", \"2\",\"3\"]\\n    _ = plt.figure(figsize=(7, 7))\\n    sns.heatmap(metrics.confusionMatrix().toArray(),\\n                cmap=\\'viridis\\',\\n                annot=True,fmt=\\'0\\',\\n                cbar=False, \\n                xticklabels=labels, \\n                yticklabels=labels)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_metrics_and_cf(predictions):\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity\"\n",
    "                                              , predictionCol=\"prediction\"\n",
    "                                              , metricName=\"accuracy\")\n",
    "\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Accuracy :\",accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    print('----------------------------')\n",
    "\n",
    "    # AUC score \n",
    "    scoreAndLabels = predictions.select('probability','Severity').rdd.map(lambda row: (float(row['Severity']),float(row['probability'][1]) ))\n",
    "    #metrics = BinaryClassificationMetrics(scoreAndLabels)\n",
    "    #auROC = metrics.areaUnderROC\n",
    "    #print('Auc_:', auROC,'\\n ----------------------')\n",
    "    \n",
    "    \n",
    "    # metrics\n",
    "    predictionAndLabels = predictions.select(\"prediction\", \"Severity\").rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    list_avg=[]\n",
    "    for i in range(4):\n",
    "        precision = metrics.precision(label=float(i))  \n",
    "        recall = metrics.recall(label=float(i))\n",
    "        f1Score= metrics.fMeasure(label=float(i)) # need .0\n",
    "        print(\"Precision for class \",i+1,\": {:.2%}\".format(precision))\n",
    "        print(\"Recall for class \",i+1,\": {:.2%}\".format(recall))\n",
    "        print(\"avg_F1-Score for class \",i+1,\": {:.2%}\".format(f1Score))\n",
    "        list_avg.append(f1Score)\n",
    "        print('----------------------------')\n",
    "    sum_=0\n",
    "    #print(list_avg)\n",
    "    for elem in list_avg:\n",
    "        sum_+=elem\n",
    "\n",
    "    avg_f1=sum_/4\n",
    "    print('----------------------')\n",
    "\n",
    "    print(\"avg_F1-Score: {:.2%}\".format(avg_f1))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    #alternativa per pc \n",
    "    print('----------------------')\n",
    "    cf= metrics.confusionMatrix().toArray()\n",
    "    print(cf)\n",
    "    print('----------------------')\n",
    "''' labels = [\"0\", \"1\", \"2\",\"3\"]\n",
    "    _ = plt.figure(figsize=(7, 7))\n",
    "    sns.heatmap(metrics.confusionMatrix().toArray(),\n",
    "                cmap='viridis',\n",
    "                annot=True,fmt='0',\n",
    "                cbar=False, \n",
    "                xticklabels=labels, \n",
    "                yticklabels=labels)''' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c422a15-60a5-493c-9ba2-d94c945f4cb7",
   "metadata": {},
   "source": [
    "### SEVERITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e538b02-ac5c-473b-8582-16e5cacfca78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def print_metrics_and_cf(predictions):\\n    prediction_counts = predictions.groupBy(\"prediction\").count()\\n    # Stampare i risultati\\n    print(\"Counts of predictions in the test set:\")\\n    prediction_counts.show()\\n    \\n    # Select (prediction, true label) and compute test error\\n    evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity\"\\n                                              , predictionCol=\"prediction\"\\n                                              , metricName=\"accuracy\")\\n\\n    accuracy = evaluator.evaluate(predictions)\\n    print(\"Accuracy :\",accuracy)\\n    print(\"Test Error = %g\" % (1.0 - accuracy))\\n    print(\\'----------------------------\\')\\n    \\n    # metrics\\n    predictionAndLabels = predictions.select(\"prediction\", \"Severity\").rdd.map(lambda x: (float(x[0]), float(x[1])))\\n    metrics = MulticlassMetrics(predictionAndLabels)\\n\\n    list_avg=[]\\n    for i in range(4):\\n        precision = metrics.precision(label=float(i))  \\n        recall = metrics.recall(label=float(i))\\n        f1Score= metrics.fMeasure(label=float(i)) # need .0\\n        print(\"Precision for class \",i+1,\": {:.2%}\".format(precision))\\n        print(\"Recall for class \",i+1,\": {:.2%}\".format(recall))\\n        print(\"avg_F1-Score for class \",i+1,\": {:.2%}\".format(f1Score))\\n        list_avg.append(f1Score)\\n        print(\\'----------------------------\\')\\n    sum_=0\\n    #print(list_avg)\\n    for elem in list_avg:\\n        sum_+=elem\\n\\n    avg_f1=sum_/4\\n    print(\\'----------------------\\')\\n\\n    print(\"avg_F1-Score: {:.2%}\".format(avg_f1))\\n\\n    # Confusion Matrix\\n    #https://www.kaggle.com/code/ashokkumarpalivela/multiclass-classification-using-pyspark\\n\\n    labels = [\"0\", \"1\", \"2\",\"3\"]\\n    _ = plt.figure(figsize=(7, 7))\\n    sns.heatmap(metrics.confusionMatrix().toArray(),\\n                cmap=\\'viridis\\',\\n                annot=True,fmt=\\'0\\',\\n                cbar=False, \\n                xticklabels=labels, \\n                yticklabels=labels)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definisco funzione le metriche \n",
    "'''def print_metrics_and_cf(predictions):\n",
    "    prediction_counts = predictions.groupBy(\"prediction\").count()\n",
    "    # Stampare i risultati\n",
    "    print(\"Counts of predictions in the test set:\")\n",
    "    prediction_counts.show()\n",
    "    \n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity\"\n",
    "                                              , predictionCol=\"prediction\"\n",
    "                                              , metricName=\"accuracy\")\n",
    "\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Accuracy :\",accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    print('----------------------------')\n",
    "    \n",
    "    # metrics\n",
    "    predictionAndLabels = predictions.select(\"prediction\", \"Severity\").rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    list_avg=[]\n",
    "    for i in range(4):\n",
    "        precision = metrics.precision(label=float(i))  \n",
    "        recall = metrics.recall(label=float(i))\n",
    "        f1Score= metrics.fMeasure(label=float(i)) # need .0\n",
    "        print(\"Precision for class \",i+1,\": {:.2%}\".format(precision))\n",
    "        print(\"Recall for class \",i+1,\": {:.2%}\".format(recall))\n",
    "        print(\"avg_F1-Score for class \",i+1,\": {:.2%}\".format(f1Score))\n",
    "        list_avg.append(f1Score)\n",
    "        print('----------------------------')\n",
    "    sum_=0\n",
    "    #print(list_avg)\n",
    "    for elem in list_avg:\n",
    "        sum_+=elem\n",
    "\n",
    "    avg_f1=sum_/4\n",
    "    print('----------------------')\n",
    "\n",
    "    print(\"avg_F1-Score: {:.2%}\".format(avg_f1))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    #https://www.kaggle.com/code/ashokkumarpalivela/multiclass-classification-using-pyspark\n",
    "\n",
    "    labels = [\"0\", \"1\", \"2\",\"3\"]\n",
    "    _ = plt.figure(figsize=(7, 7))\n",
    "    sns.heatmap(metrics.confusionMatrix().toArray(),\n",
    "                cmap='viridis',\n",
    "                annot=True,fmt='0',\n",
    "                cbar=False, \n",
    "                xticklabels=labels, \n",
    "                yticklabels=labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "776fa7ee-dbd6-415b-bd81-d76a66ceaf36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_Lat', 'Start_Lng', 'Distance_mi', 'Temperature_F', 'Humidity_perc', 'Visibility_mi', 'Wind_Speed_mph', 'Precipitation_in', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'month', 'hour', 'Working_Weekend', 'Astronomical_Twilight', 'Weather_Condition_1hot']\n"
     ]
    }
   ],
   "source": [
    "# colonne numeriche \n",
    "num_col = [item[0] for item in df_class.dtypes if not item[1].startswith('string')]\n",
    "num_col.remove(\"Severity\")\n",
    "\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27425a40-ece3-4c6f-93f4-182fff9dd6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scalo Severity di 1 in modo da farlo partire da 0 \n",
    "df_class= df_class.withColumn(\"Severity\", col(\"Severity\") - 1)\n",
    "# la classe 2 adesso diventa la 1 \n",
    "\n",
    "#df_class.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99413e-1292-47a7-948f-460c74007765",
   "metadata": {},
   "source": [
    "### A_Sbilanciato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27cb1650-e9ad-4355-b213-5f3f15783fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=num_col, outputCol=\"features\")\n",
    "\n",
    "output_dataset = assembler.transform(df_class)\n",
    "\n",
    "classificationData = output_dataset.select(\"features\", \"Severity\")\n",
    "\n",
    "#classificationData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd9dacb6-2ca1-4ab9-bee7-f234cc6fb8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = classificationData.randomSplit([0.7, 0.3],seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2751f28-d81c-4db9-9560-46aa58001021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Severity|\n",
      "+--------------------+--------+\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c22abb03-0fb5-4c02-b289-8827e8dde12d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Severity|\n",
      "+--------------------+--------+\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "|(28,[0,1,2,3,4,5,...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba4e3dcd-7655-42a8-8bae-83efa4356160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "g=trainingData.groupBy('Severity').agg(F.count('Severity').alias('Count'))\n",
    "g=g.sort('Severity')\n",
    "g_p=g.toPandas()\n",
    "\n",
    "n_0=g_p.iloc[0,1]\n",
    "n_1=g_p.iloc[1,1]\n",
    "n_2=g_p.iloc[2,1]\n",
    "n_3=g_p.iloc[3,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4cbaa-c98b-4f0b-b887-cdfcc57668eb",
   "metadata": {},
   "source": [
    "### A_DT default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f78fc5e-5207-4953-9ce0-0e284255d8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9440947084950863\n",
      "Test Error = 0.0559053\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davide\\anaconda3\\envs\\pyspark_env\\Lib\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for class  1 : 61.02%\n",
      "Recall for class  1 : 17.83%\n",
      "avg_F1-Score for class  1 : 27.60%\n",
      "----------------------------\n",
      "Precision for class  2 : 95.69%\n",
      "Recall for class  2 : 98.61%\n",
      "avg_F1-Score for class  2 : 97.13%\n",
      "----------------------------\n",
      "Precision for class  3 : 55.88%\n",
      "Recall for class  3 : 41.99%\n",
      "avg_F1-Score for class  3 : 47.95%\n",
      "----------------------------\n",
      "Precision for class  4 : 65.50%\n",
      "Recall for class  4 : 10.30%\n",
      "avg_F1-Score for class  4 : 17.80%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 47.62%\n",
      "----------------------\n",
      "[[2.52000e+02 1.08000e+03 8.10000e+01 0.00000e+00]\n",
      " [1.01000e+02 1.05812e+05 1.31000e+03 7.90000e+01]\n",
      " [6.00000e+01 2.37700e+03 1.76400e+03 0.00000e+00]\n",
      " [0.00000e+00 1.30400e+03 2.00000e+00 1.50000e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\")\n",
    "dt = dt.fit(trainingData)\n",
    "predictions = dt.transform(testData)\n",
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "616af1d1-bdcc-4c67-a9d3-0935dd482dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.0064, 1: 0.0642, 2: 0.7365, 3: 0.0024, 6: 0.0409, 10: 0.0081, 19: 0.0138, 20: 0.0805, 21: 0.0215, 22: 0.0256})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688400b-f662-4fb0-800b-1f60f1ddbcdb",
   "metadata": {},
   "source": [
    "### A___ DT testo configurazioni diverse di parametri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0428e9-206e-4798-9d73-0d7b144a812a",
   "metadata": {},
   "source": [
    "### A_a)Grid Search con pesi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f59e41-faff-4888-b8ec-958d42253737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a518183b-28dd-4d63-94d8-0ddcbec24ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n=df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0f637d-6683-47c5-bff8-85a9662c2ab4",
   "metadata": {},
   "source": [
    "##### definisco i pesi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "929fa1a0-f09e-417b-afd7-fedc3246c07d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Severity| Count|\n",
      "+--------+------+\n",
      "|       3|  3275|\n",
      "|       0|  3407|\n",
      "|       2|  9871|\n",
      "|       1|250512|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "g=trainingData.groupBy('Severity').agg(F.count('Severity').alias('Count'))\n",
    "g.sort('Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18900c44-1d4f-4fe7-98e9-220009e4ed5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingData_w = trainingData.withColumn(\"weights1\", lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85bd074e-67bc-4247-b38d-0436519cb17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creiamo la colonna 'weights' basata sulla frequenza delle classi\n",
    "#trainingData_w\n",
    "trainingData_w = trainingData_w.withColumn(\"weights2\", when(trainingData[\"Severity\"] == 1, 1.0)\n",
    "    .when(trainingData[\"Severity\"] == 0, 267020 / 3407)  # Calcolo del peso per la classe 1\n",
    "    .when(trainingData[\"Severity\"] == 2, 267020 / 9871)  # Calcolo del peso per la classe 3\n",
    "    .when(trainingData[\"Severity\"] == 3, 267020 / 3275)  # Calcolo del peso per la classe 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77062d9c-c744-4acf-ac98-b24dd2de9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA VEDERE SE MI SERVE  !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Creiamo la colonna 'weights' basata sulla frequenza delle classi\n",
    "#trainingData = trainingData.withColumn(\"weights3\", when(trainingData[\"Severity\"] == 4,108039/1933).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4bc19d7-b903-48f2-9501-92c3e87738a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza sul set di test utilizzando il miglior modello = 94.66%\n"
     ]
    }
   ],
   "source": [
    "param_grid = (ParamGridBuilder()\n",
    "              #.addGrid(dt.maxDepth, [5,10,15,20,25,30])\n",
    "              .addGrid(dt.maxDepth, [5,20,30])\n",
    "              .addGrid(dt.maxBins, [32, 64])\n",
    "              #.addGrid(dt.minInstancesPerNode, [round(0.01*n),round(0.005*n),round(0.001*n),round(0.02*n)])\n",
    "              .addGrid(dt.minInstancesPerNode, [round(0.001*n),round(0.02*n)])\n",
    "              .addGrid(dt.weightCol, ['weights1','weights2']) #SOLO 2 COLONNE DEI PESI \n",
    "              .addGrid(dt.impurity, ['entropy', 'gini'])\n",
    "              .build())\n",
    "\n",
    "# Crea il CrossValidator\n",
    "cross_validator = CrossValidator(estimator=dt,\n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=MulticlassClassificationEvaluator(labelCol=\"Severity\", \n",
    "                                                                             predictionCol=\"prediction\", \n",
    "                                                                             metricName=\"accuracy\"),\n",
    "                                 numFolds=5,\n",
    "                                 )\n",
    "\n",
    "# Esegui la cross-validation e scegli il miglior set di parametri\n",
    "cv_model = cross_validator.fit(trainingData_w)\n",
    "\n",
    "# Ottieni il miglior modello dalla cross-validation\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Esegui predizioni sul set di test utilizzando il miglior modello\n",
    "result = best_model.transform(testData)\n",
    "\n",
    "# Valuta l'accuratezza sul set di test\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity\", \n",
    "                                              predictionCol=\"prediction\", \n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(result)\n",
    "print(\"Accuratezza sul set di test utilizzando il miglior modello = {:.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ae4f6ce-cf1b-4287-949d-e1780be7b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.0539, 1: 0.0747, 2: 0.7456, 3: 0.0147, 4: 0.007, 10: 0.0036, 19: 0.0052, 20: 0.0644, 21: 0.016, 22: 0.0148})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.featureImportances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d88bf98-c79c-4e8c-b65e-6ff29789ed06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=0.0),\n",
       " Row(prediction=2.0),\n",
       " Row(prediction=1.0),\n",
       " Row(prediction=3.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('prediction').distinct().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffedb2f5-57c8-48d2-8931-5a674d7784a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9465603469380618\n",
      "Test Error = 0.0534397\n",
      "----------------------------\n",
      "Precision for class  1 : 50.82%\n",
      "Recall for class  1 : 39.28%\n",
      "avg_F1-Score for class  1 : 44.31%\n",
      "----------------------------\n",
      "Precision for class  2 : 96.71%\n",
      "Recall for class  2 : 98.08%\n",
      "avg_F1-Score for class  2 : 97.39%\n",
      "----------------------------\n",
      "Precision for class  3 : 53.24%\n",
      "Recall for class  3 : 53.56%\n",
      "avg_F1-Score for class  3 : 53.40%\n",
      "----------------------------\n",
      "Precision for class  4 : 90.46%\n",
      "Recall for class  4 : 14.97%\n",
      "avg_F1-Score for class  4 : 25.69%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 55.20%\n",
      "----------------------\n",
      "[[5.55000e+02 5.46000e+02 3.12000e+02 0.00000e+00]\n",
      " [3.81000e+02 1.05237e+05 1.66100e+03 2.30000e+01]\n",
      " [1.56000e+02 1.79500e+03 2.25000e+03 0.00000e+00]\n",
      " [0.00000e+00 1.23500e+03 3.00000e+00 2.18000e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "print_metrics_and_cf(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7432b033-12b1-4619-a691-00aefbb09285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|       0.0|  1092|\n",
      "|       2.0|  4226|\n",
      "|       1.0|108813|\n",
      "|       3.0|   241|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_counts = result.groupBy(\"prediction\").count()\n",
    "\n",
    "# Stampare i risultati\n",
    "result_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9278257-76ef-44ed-a356-d32b1275b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Severity| count|\n",
      "+--------+------+\n",
      "|       1|107302|\n",
      "|       3|  1456|\n",
      "|       2|  4201|\n",
      "|       0|  1413|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_counts = result.groupBy(\"Severity\").count()\n",
    "\n",
    "# Stampare i risultati\n",
    "result_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73af0d9-8c3e-481b-b781-9ebace50df4b",
   "metadata": {},
   "source": [
    "### A_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "296f6aaf-76fd-4276-bc29-6a41065c5b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9422236211660197\n",
      "Test Error = 0.0577764\n",
      "----------------------------\n",
      "Precision for class  1 : 45.75%\n",
      "Recall for class  1 : 44.52%\n",
      "avg_F1-Score for class  1 : 45.12%\n",
      "----------------------------\n",
      "Precision for class  2 : 97.02%\n",
      "Recall for class  2 : 97.23%\n",
      "avg_F1-Score for class  2 : 97.13%\n",
      "----------------------------\n",
      "Precision for class  3 : 55.28%\n",
      "Recall for class  3 : 54.99%\n",
      "avg_F1-Score for class  3 : 55.13%\n",
      "----------------------------\n",
      "Precision for class  4 : 38.45%\n",
      "Recall for class  4 : 34.07%\n",
      "avg_F1-Score for class  4 : 36.13%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 58.38%\n",
      "----------------------\n",
      "[[6.29000e+02 5.79000e+02 2.05000e+02 0.00000e+00]\n",
      " [5.34000e+02 1.04329e+05 1.65200e+03 7.87000e+02]\n",
      " [2.08000e+02 1.67600e+03 2.31000e+03 7.00000e+00]\n",
      " [4.00000e+00 9.44000e+02 1.20000e+01 4.96000e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "dt_param1 = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\",\n",
    "                                  maxDepth=20,\n",
    "                                  maxBins=32)\n",
    "                                   \n",
    "dt_param1 = dt_param1.fit(trainingData)\n",
    "predictions_param1 = dt_param1.transform(testData)\n",
    "print_metrics_and_cf(predictions_param1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d4f8edf-2dd6-45fc-b929-f204d167a83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.1168, 1: 0.1272, 2: 0.3201, 3: 0.084, 4: 0.071, 5: 0.0153, 6: 0.0606, 7: 0.0032, 8: 0.0014, 9: 0.0003, 10: 0.0078, 11: 0.0003, 12: 0.0099, 13: 0.0002, 14: 0.0018, 16: 0.0029, 17: 0.0049, 18: 0.0002, 19: 0.0145, 20: 0.0575, 21: 0.0709, 22: 0.0169, 23: 0.003, 24: 0.0039, 25: 0.0034, 26: 0.001, 27: 0.0008})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_param1.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b36b21-96da-4b7a-ae41-cdb244da7e0a",
   "metadata": {},
   "source": [
    "### A_c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eae009ec-172c-4e55-9ec7-131d81a038c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Severity| Count|\n",
      "+--------+------+\n",
      "|       3|  3275|\n",
      "|       0|  3407|\n",
      "|       2|  9871|\n",
      "|       1|250512|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "g=trainingData.groupBy('Severity').agg(F.count('Severity').alias('Count'))\n",
    "g.sort('Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59b17518-d77e-4bd6-b412-46a3f80631f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_w = trainingData_w.withColumn(\"weights2\", when(trainingData[\"Severity\"] == 1, 1.0)\n",
    "    .when(trainingData[\"Severity\"] == 0, 267020 / 3335)  # Calcolo del peso per la classe 1\n",
    "    .when(trainingData[\"Severity\"] == 2, 267020 / 9857)  # Calcolo del peso per la classe 3\n",
    "    .when(trainingData[\"Severity\"] == 3, 267020 / 3272)  # Calcolo del peso per la classe 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54515ae-d43d-4406-8d9f-5a13bbde4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Weights\n",
    "trainingData_w = trainingData_w.withColumn(\"weights2\", when(trainingData[\"Severity\"] == 1, 1.0)\n",
    "    .when(trainingData[\"Severity\"] == 0, 267020 / 3407)  # Calcolo del peso per la classe 1\n",
    "    .when(trainingData[\"Severity\"] == 2, 267020 / 9871)  # Calcolo del peso per la classe 3\n",
    "    .when(trainingData[\"Severity\"] == 3, 267020 / 3275)  # Calcolo del peso per la classe 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3ffea29-9fce-4d78-9c04-607250f30bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9262756618752842\n",
      "Test Error = 0.0737243\n",
      "----------------------------\n",
      "Precision for class  1 : 40.99%\n",
      "Recall for class  1 : 44.59%\n",
      "avg_F1-Score for class  1 : 42.71%\n",
      "----------------------------\n",
      "Precision for class  2 : 97.02%\n",
      "Recall for class  2 : 95.52%\n",
      "avg_F1-Score for class  2 : 96.27%\n",
      "----------------------------\n",
      "Precision for class  3 : 48.88%\n",
      "Recall for class  3 : 50.80%\n",
      "avg_F1-Score for class  3 : 49.82%\n",
      "----------------------------\n",
      "Precision for class  4 : 24.06%\n",
      "Recall for class  4 : 46.70%\n",
      "avg_F1-Score for class  4 : 31.76%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 55.14%\n",
      "----------------------\n",
      "[[6.30000e+02 5.70000e+02 2.12000e+02 1.00000e+00]\n",
      " [6.60000e+02 1.02496e+05 2.00900e+03 2.13700e+03]\n",
      " [2.46000e+02 1.81300e+03 2.13400e+03 8.00000e+00]\n",
      " [1.00000e+00 7.64000e+02 1.10000e+01 6.80000e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "\n",
    "dt_param1 = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\",\n",
    "                                  maxDepth=30,\n",
    "                                  maxBins=32,\n",
    "                                weightCol='weights2'  \n",
    "                                  )\n",
    "                                   \n",
    "\n",
    "dt_param1 = dt_param1.fit(trainingData_w)\n",
    "predictions_param1 = dt_param1.transform(testData)\n",
    "print_metrics_and_cf(predictions_param1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca5b5860-77ed-4fb6-8c33-2f080f3e5f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.1272, 1: 0.1, 2: 0.3045, 3: 0.0581, 4: 0.058, 5: 0.0115, 6: 0.0427, 7: 0.0027, 8: 0.0008, 9: 0.0003, 10: 0.0058, 11: 0.0002, 12: 0.0091, 13: 0.0001, 14: 0.0014, 16: 0.0016, 17: 0.0054, 18: 0.0, 19: 0.0133, 20: 0.1276, 21: 0.0752, 22: 0.0351, 23: 0.0083, 24: 0.0049, 25: 0.0036, 26: 0.001, 27: 0.0015})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_param1.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa8747-eaf2-4161-a4c0-cb5f3f95adce",
   "metadata": {},
   "source": [
    "### B_ RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e6a6255-c296-4ff1-9698-83df250ed0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9381841709509321\n",
      "Test Error = 0.0618158\n",
      "----------------------------\n",
      "Precision for class  1 : 0.00%\n",
      "Recall for class  1 : 0.00%\n",
      "avg_F1-Score for class  1 : 0.00%\n",
      "----------------------------\n",
      "Precision for class  2 : 93.82%\n",
      "Recall for class  2 : 100.00%\n",
      "avg_F1-Score for class  2 : 96.81%\n",
      "----------------------------\n",
      "Precision for class  3 : 0.00%\n",
      "Recall for class  3 : 0.00%\n",
      "avg_F1-Score for class  3 : 0.00%\n",
      "----------------------------\n",
      "Precision for class  4 : 0.00%\n",
      "Recall for class  4 : 0.00%\n",
      "avg_F1-Score for class  4 : 0.00%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 24.20%\n",
      "----------------------\n",
      "[[     0.   1413.      0.      0.]\n",
      " [     0. 107302.      0.      0.]\n",
      " [     0.   4201.      0.      0.]\n",
      " [     0.   1456.      0.      0.]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"Severity\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11885a76-289e-4118-b49a-fb182dc478d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.0481, 1: 0.0234, 2: 0.684, 3: 0.0288, 4: 0.0488, 5: 0.0011, 6: 0.0035, 7: 0.0011, 8: 0.0, 10: 0.0065, 12: 0.002, 14: 0.0012, 16: 0.0005, 17: 0.0004, 18: 0.0007, 19: 0.0232, 20: 0.1046, 21: 0.0202, 22: 0.0017, 23: 0.0003})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef7e49-6a05-4ea4-a20e-adaf597d51d4",
   "metadata": {},
   "source": [
    "### B_i) TUNING RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ad5b51b-cefc-4c98-ae99-59e69321d163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9535550659252264\n",
      "Test Error = 0.0464449\n",
      "----------------------------\n",
      "Precision for class  1 : 59.77%\n",
      "Recall for class  1 : 43.74%\n",
      "avg_F1-Score for class  1 : 50.51%\n",
      "----------------------------\n",
      "Precision for class  2 : 96.65%\n",
      "Recall for class  2 : 98.73%\n",
      "avg_F1-Score for class  2 : 97.68%\n",
      "----------------------------\n",
      "Precision for class  3 : 65.49%\n",
      "Recall for class  3 : 49.15%\n",
      "avg_F1-Score for class  3 : 56.16%\n",
      "----------------------------\n",
      "Precision for class  4 : 76.60%\n",
      "Recall for class  4 : 30.36%\n",
      "avg_F1-Score for class  4 : 43.48%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 61.96%\n",
      "----------------------\n",
      "[[6.18000e+02 6.26000e+02 1.69000e+02 0.00000e+00]\n",
      " [3.17000e+02 1.05935e+05 9.16000e+02 1.34000e+02]\n",
      " [9.90000e+01 2.03600e+03 2.06500e+03 1.00000e+00]\n",
      " [0.00000e+00 1.01100e+03 3.00000e+00 4.42000e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"Severity\", featuresCol=\"features\", numTrees=20,maxDepth=20, seed=10\n",
    "                           )\n",
    "# Train model.  This also runs the indexers.\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41644aca-4fef-4d47-b9d1-0e6ebc3fba1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.0925, 1: 0.0897, 2: 0.3808, 3: 0.0684, 4: 0.0621, 5: 0.0166, 6: 0.0519, 7: 0.0045, 8: 0.0018, 9: 0.0002, 10: 0.0076, 11: 0.0004, 12: 0.0079, 13: 0.0005, 14: 0.0024, 15: 0.0, 16: 0.0041, 17: 0.0053, 18: 0.0003, 19: 0.0148, 20: 0.0741, 21: 0.0698, 22: 0.0162, 23: 0.0073, 24: 0.0082, 25: 0.008, 26: 0.0022, 27: 0.0024})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663dfcbd-597f-4b13-a52e-2870cee7d595",
   "metadata": {},
   "source": [
    "### C_ NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb0cfe-4066-4555-bc48-f4ca51e5bc93",
   "metadata": {},
   "source": [
    "###### data preparation for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4f00ba9-e63e-47a2-930f-7edac7343982",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=['Start_Time','City','County','State','Wind_Direction','day_of_the_week','season']\n",
    "df_class=df.drop(*to_drop)\n",
    "colonne_booleane = ['Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal']\n",
    "\n",
    "# Converti le colonne booleane in numeriche\n",
    "for col_name in colonne_booleane:\n",
    "    df_class = df_class.withColumn(col_name, col(col_name).cast(\"int\"))\n",
    "\n",
    "\n",
    "df_class = df_class.withColumn(\"Astronomical_Twilight\", when(df_class[\"Astronomical_Twilight\"] == 'Day', 0).otherwise(1))\n",
    "df_class = df_class.withColumn(\"Working_Weekend\", when(df_class[\"Working_Weekend\"] == 'WorkingDay', 0).otherwise(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indexer = StringIndexer(inputCol='Weather_Condition', outputCol='class_numeric')\n",
    "indexer_fitted = indexer.fit(df_class)\n",
    "df_indexed = indexer_fitted.transform(df_class)\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=['class_numeric'], outputCols=['class_onehot'],dropLast=False)\n",
    "df_onehot = encoder.fit(df_indexed).transform(df_indexed)\n",
    "\n",
    "\n",
    "df_col_onehot = df_onehot.select('*', vector_to_array('class_onehot').alias('col_onehot'))\n",
    "\n",
    "num_categories = len(df_col_onehot.first()['col_onehot'])   # 3\n",
    "cols_expanded = [(F.col('col_onehot')[i].alias(f'{indexer_fitted.labels[i]}')) for i in range(num_categories)]\n",
    "df_cols_onehot = df_col_onehot.select('Severity',\n",
    " 'Start_Lat',\n",
    " 'Start_Lng',\n",
    " 'Distance_mi',\n",
    " 'Temperature_F',\n",
    " 'Humidity_perc',\n",
    " 'Visibility_mi',\n",
    " 'Wind_Speed_mph',\n",
    " 'Precipitation_in',\n",
    " 'Amenity',\n",
    " 'Bump',\n",
    " 'Crossing',\n",
    " 'Give_Way',\n",
    " 'Junction',\n",
    " 'No_Exit',\n",
    " 'Railway',\n",
    " 'Roundabout',\n",
    " 'Station',\n",
    " 'Stop',\n",
    " 'Traffic_Calming',\n",
    " 'Traffic_Signal',\n",
    " 'month',\n",
    " 'hour',\n",
    " 'Working_Weekend',\n",
    " 'Astronomical_Twilight', *cols_expanded)\n",
    "\n",
    "\n",
    "num_col = [item[0] for item in df_cols_onehot.dtypes if not item[1].startswith('string')]\n",
    "num_col.remove(\"Severity\")\n",
    "\n",
    "df_MLP= df_cols_onehot.withColumn(\"Severity\", col(\"Severity\") - 1)\n",
    "#df_MLP.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a6f7f7e-fd4f-4b95-a68a-fc5c4b2bdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MLP_binary=df_MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65965b8a-d663-4e46-8ff4-626f30ba210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Severity| count|\n",
      "+--------+------+\n",
      "|       1|357814|\n",
      "|       3|  4731|\n",
      "|       2| 14072|\n",
      "|       0|  4820|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "severity_counts = df_MLP.groupBy(\"Severity\").count()\n",
    "severity_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba76576c-b738-4030-9611-95a11b1adfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_nn = VectorAssembler(inputCols=num_col, outputCol=\"features\")\n",
    "\n",
    "output_dataset_nn = assembler_nn.transform(df_MLP)\n",
    "\n",
    "classificationData_nn = output_dataset_nn.select(\"features\", \"Severity\")\n",
    "\n",
    "#classificationData_nn.show(truncate=False)\n",
    "(trainingData_nn, testData_nn) = classificationData_nn.randomSplit([0.7, 0.3],seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fdc1a5-54aa-4c66-9a10-ffafe6ad8208",
   "metadata": {},
   "source": [
    "###### Run NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f3a7e14-c7a2-4b40-91a6-567333e7d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9377966590617051\n",
      "Test Error = 0.0622033\n",
      "----------------------------\n",
      "Precision for class  1 : 2.78%\n",
      "Recall for class  1 : 0.07%\n",
      "avg_F1-Score for class  1 : 0.13%\n",
      "----------------------------\n",
      "Precision for class  2 : 93.81%\n",
      "Recall for class  2 : 99.97%\n",
      "avg_F1-Score for class  2 : 96.79%\n",
      "----------------------------\n",
      "Precision for class  3 : 0.00%\n",
      "Recall for class  3 : 0.00%\n",
      "avg_F1-Score for class  3 : 0.00%\n",
      "----------------------------\n",
      "Precision for class  4 : 0.00%\n",
      "Recall for class  4 : 0.00%\n",
      "avg_F1-Score for class  4 : 0.00%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 24.23%\n",
      "----------------------\n",
      "[[1.00000e+00 1.46700e+03 0.00000e+00 0.00000e+00]\n",
      " [3.50000e+01 1.07282e+05 2.00000e+00 0.00000e+00]\n",
      " [0.00000e+00 4.16600e+03 0.00000e+00 0.00000e+00]\n",
      " [0.00000e+00 1.44600e+03 0.00000e+00 0.00000e+00]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# MLP Layers  -> output layer must have the same number of units of the Severity classes\n",
    "layers = [len(num_col),4]\n",
    "\n",
    "# Create the Multilayer Perceptron Classifier and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(\n",
    "    layers=layers,\n",
    "    labelCol=\"Severity\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=100,  \n",
    "    tol=1e-6,\n",
    "    seed=None,\n",
    "    blockSize=32,\n",
    "    stepSize=0.03,  \n",
    "    solver=\"l-bfgs\",\n",
    "    initialWeights=None,\n",
    "    probabilityCol=\"probability\",\n",
    "    rawPredictionCol=\"rawPrediction\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = trainer.fit(trainingData_nn)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions= model.transform(testData_nn)\n",
    "\n",
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c216b7-ccea-4654-99c5-0b6a1d052c7d",
   "metadata": {},
   "source": [
    " ## U_ UNDERSAMPLING\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "041193ee-0d7e-4e3d-a022-cd08253d0ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8728373e-ec3e-4d37-8656-dc5d2d5844cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Severity| Count|\n",
      "+--------+------+\n",
      "|       0|  3407|\n",
      "|       1|250512|\n",
      "|       2|  9871|\n",
      "|       3|  3275|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "g=trainingData.groupBy('Severity').agg(F.count('Severity').alias('Count'))\n",
    "g=g.sort('Severity')\n",
    "g.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e191e61-9edc-4850-bd7b-889d71637007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_p=g.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b7ef483-0a01-4280-8fb6-4aa02a9faa66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_0=g_p.iloc[0,1]\n",
    "n_1=g_p.iloc[1,1]\n",
    "n_2=g_p.iloc[2,1]\n",
    "n_3=g_p.iloc[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766337b0-9121-473b-919f-4254f853aa83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "und=(n_0+n_2+n_3)/3 # si applica semplicemente la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43749e42-6895-4928-893a-efc901922be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_und = trainingData.sampleBy('Severity', fractions={0:1.0 ,1: und/n_1 , 2:1.0, 3:1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f4ee3-82df-4b98-a138-53cd798704fe",
   "metadata": {},
   "source": [
    "### U_1 DT base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dacc9011-01fa-4a8e-811e-716ca683c0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\")\n",
    "\n",
    "dt = dt.fit(train_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0246c31b-6ada-4f77-979e-336e59c01496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = dt.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9b72ee9-cfe4-496e-91d4-56a1c3828e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8015510789354038\n",
      "Test Error = 0.198449\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davide\\anaconda3\\envs\\pyspark_env\\Lib\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for class  1 : 37.42%\n",
      "Recall for class  1 : 71.13%\n",
      "avg_F1-Score for class  1 : 49.04%\n",
      "----------------------------\n",
      "Precision for class  2 : 98.90%\n",
      "Recall for class  2 : 80.68%\n",
      "avg_F1-Score for class  2 : 88.87%\n",
      "----------------------------\n",
      "Precision for class  3 : 34.63%\n",
      "Recall for class  3 : 76.55%\n",
      "avg_F1-Score for class  3 : 47.69%\n",
      "----------------------------\n",
      "Precision for class  4 : 5.93%\n",
      "Recall for class  4 : 60.58%\n",
      "avg_F1-Score for class  4 : 10.81%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 49.10%\n",
      "----------------------\n",
      "[[1.0050e+03 9.5000e+01 3.1000e+02 3.0000e+00]\n",
      " [1.0710e+03 8.6572e+04 5.7400e+03 1.3919e+04]\n",
      " [6.0900e+02 3.1600e+02 3.2160e+03 6.0000e+01]\n",
      " [1.0000e+00 5.5300e+02 2.0000e+01 8.8200e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11ba9e7c-d4a3-4f0e-99b4-fa1c16b825e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.084, 1: 0.1177, 2: 0.608, 3: 0.0089, 19: 0.0214, 20: 0.1163, 21: 0.0052, 22: 0.0304, 23: 0.0081})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1c84cbd-a41c-48da-ba49-3ceb5181c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le features pi importanti per la predizione sono :\n",
      "Distance_mi con un'importanza dello 0.6079570635876781\n",
      "Start_Lng con un'importanza dello 0.11770419100136396\n",
      "month con un'importanza dello 0.11629488733169649\n",
      "Start_Lat con un'importanza dello 0.08395371791912863\n",
      "Working_Weekend con un'importanza dello 0.030425593021708705\n",
      "Traffic_Signal con un'importanza dello 0.021436394764437153\n",
      "Temperature_F con un'importanza dello 0.00887952455729292\n",
      "Astronomical_Twilight con un'importanza dello 0.008099003932141613\n",
      "hour con un'importanza dello 0.005249623884552483\n"
     ]
    }
   ],
   "source": [
    "feat_imp=dt.featureImportances\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "non_zero_elements = [(index, value) for index, value in zip(feat_imp.indices, feat_imp.values) if value != 0]\n",
    "sorted_non_zero_elements = sorted(non_zero_elements, key=lambda x: x[1], reverse=True)\n",
    "print('Le features pi importanti per la predizione sono :')\n",
    "for el in sorted_non_zero_elements:\n",
    "    if el[0]>=24:\n",
    "        print(num_col[len(num_col)-1], 'con un\\'importanza dello', el[1])\n",
    "    else:\n",
    "        print(num_col[el[0]], 'con un\\'importanza dello', el[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b565d4c-4bd2-45b1-9762-ad8447e61f4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### U_2 Random forest base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00a4d602-cc07-4d48-94dd-827c3563e94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"Severity\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = rf.fit(train_und)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e163f4b4-c368-44e5-b910-e5db902bc7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.850225579687336\n",
      "Test Error = 0.149774\n",
      "----------------------------\n",
      "Precision for class  1 : 51.29%\n",
      "Recall for class  1 : 31.00%\n",
      "avg_F1-Score for class  1 : 38.64%\n",
      "----------------------------\n",
      "Precision for class  2 : 98.77%\n",
      "Recall for class  2 : 86.05%\n",
      "avg_F1-Score for class  2 : 91.97%\n",
      "----------------------------\n",
      "Precision for class  3 : 33.10%\n",
      "Recall for class  3 : 89.67%\n",
      "avg_F1-Score for class  3 : 48.36%\n",
      "----------------------------\n",
      "Precision for class  4 : 8.11%\n",
      "Recall for class  4 : 48.21%\n",
      "avg_F1-Score for class  4 : 13.89%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 48.21%\n",
      "----------------------\n",
      "[[4.3800e+02 9.5000e+01 8.6700e+02 1.3000e+01]\n",
      " [3.8300e+02 9.2335e+04 6.7330e+03 7.8510e+03]\n",
      " [3.2000e+01 3.1500e+02 3.7670e+03 8.7000e+01]\n",
      " [1.0000e+00 7.4100e+02 1.2000e+01 7.0200e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4846cd94-010f-4622-b986-a1f6f9dbae8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.0601, 1: 0.0398, 2: 0.6021, 3: 0.0328, 4: 0.0037, 5: 0.0003, 6: 0.0121, 7: 0.001, 8: 0.0005, 10: 0.0133, 12: 0.0006, 14: 0.0005, 16: 0.0015, 17: 0.0068, 18: 0.0001, 19: 0.0236, 20: 0.1697, 21: 0.0134, 22: 0.0166, 23: 0.0008, 25: 0.0004, 27: 0.0001})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed8044bd-8c9b-4c51-bd6e-9d517623b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le features pi importanti per la predizione sono :\n",
      "Distance_mi con un'importanza dello 0.6021298960645595\n",
      "month con un'importanza dello 0.16965688407223428\n",
      "Start_Lat con un'importanza dello 0.06006015464731429\n",
      "Start_Lng con un'importanza dello 0.039790476833249024\n",
      "Temperature_F con un'importanza dello 0.03279361148756961\n",
      "Traffic_Signal con un'importanza dello 0.02364886010816531\n",
      "Working_Weekend con un'importanza dello 0.01660877635558642\n",
      "hour con un'importanza dello 0.0133927382480035\n",
      "Crossing con un'importanza dello 0.01334245350087565\n",
      "Wind_Speed_mph con un'importanza dello 0.0121125874923735\n",
      "Stop con un'importanza dello 0.006815860127949847\n",
      "Humidity_perc con un'importanza dello 0.003691973339777941\n",
      "Station con un'importanza dello 0.0014562540455305187\n",
      "Precipitation_in con un'importanza dello 0.0009929584067117163\n",
      "Astronomical_Twilight con un'importanza dello 0.0007903088639355463\n",
      "Junction con un'importanza dello 0.0006367021440046624\n",
      "Amenity con un'importanza dello 0.0005376172412986885\n",
      "Railway con un'importanza dello 0.0005203923145143919\n",
      "Weather_Condition_1hot con un'importanza dello 0.0004250456376379804\n",
      "Visibility_mi con un'importanza dello 0.00034998315177653817\n",
      "Weather_Condition_1hot con un'importanza dello 0.00014285678320021493\n",
      "Traffic_Calming con un'importanza dello 0.00010360913373092537\n"
     ]
    }
   ],
   "source": [
    "feat_imp=model.featureImportances\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "non_zero_elements = [(index, value) for index, value in zip(feat_imp.indices, feat_imp.values) if value != 0]\n",
    "sorted_non_zero_elements = sorted(non_zero_elements, key=lambda x: x[1], reverse=True)\n",
    "print('Le features pi importanti per la predizione sono :')\n",
    "for el in sorted_non_zero_elements:\n",
    "    if el[0]>=24:\n",
    "        print(num_col[len(num_col)-1], 'con un\\'importanza dello', el[1])\n",
    "    else:\n",
    "        print(num_col[el[0]], 'con un\\'importanza dello', el[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c7254-f2af-422a-94f2-65ddf7bc100c",
   "metadata": {},
   "source": [
    "#### U_2)_a) Ranodom Forest Tuning aumento max depth e numero di alberi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2863e4aa-4b5a-44ec-ae8c-b27e2f1978df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8357989717763089\n",
      "Test Error = 0.164201\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davide\\anaconda3\\envs\\pyspark_env\\Lib\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for class  1 : 40.78%\n",
      "Recall for class  1 : 68.58%\n",
      "avg_F1-Score for class  1 : 51.15%\n",
      "----------------------------\n",
      "Precision for class  2 : 99.18%\n",
      "Recall for class  2 : 83.83%\n",
      "avg_F1-Score for class  2 : 90.86%\n",
      "----------------------------\n",
      "Precision for class  3 : 31.07%\n",
      "Recall for class  3 : 89.00%\n",
      "avg_F1-Score for class  3 : 46.06%\n",
      "----------------------------\n",
      "Precision for class  4 : 10.09%\n",
      "Recall for class  4 : 64.22%\n",
      "avg_F1-Score for class  4 : 17.44%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 51.38%\n",
      "----------------------\n",
      "[[9.6900e+02 7.2000e+01 3.6200e+02 1.0000e+01]\n",
      " [1.1880e+03 8.9949e+04 7.8810e+03 8.2840e+03]\n",
      " [2.1400e+02 2.0800e+02 3.7390e+03 4.0000e+01]\n",
      " [5.0000e+00 4.6200e+02 5.4000e+01 9.3500e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"Severity\", featuresCol=\"features\", numTrees=20,maxDepth=20, seed=10\n",
    "                           )\n",
    "# Train model.  This also runs the indexers.\n",
    "model = rf.fit(train_und)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c22ba9bf-f7c4-4352-9e3d-c9b07089094c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.1152, 1: 0.108, 2: 0.3236, 3: 0.0591, 4: 0.0492, 5: 0.0125, 6: 0.0404, 7: 0.0033, 8: 0.0017, 9: 0.0002, 10: 0.0107, 11: 0.0003, 12: 0.0084, 13: 0.0002, 14: 0.0015, 16: 0.0032, 17: 0.0064, 18: 0.0003, 19: 0.0174, 20: 0.1213, 21: 0.0673, 22: 0.0214, 23: 0.0093, 24: 0.0077, 25: 0.0072, 26: 0.0022, 27: 0.002})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b56f1f1c-248a-4d63-b699-51e5f0fb1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le features pi importanti per la predizione sono :\n",
      "Distance_mi con un'importanza dello 0.32364114144043005\n",
      "month con un'importanza dello 0.12128154580107002\n",
      "Start_Lat con un'importanza dello 0.1151541824871002\n",
      "Start_Lng con un'importanza dello 0.10795877543782732\n",
      "hour con un'importanza dello 0.06728564837311637\n",
      "Temperature_F con un'importanza dello 0.05911022325052982\n",
      "Humidity_perc con un'importanza dello 0.0491736564692269\n",
      "Wind_Speed_mph con un'importanza dello 0.040440387788528126\n",
      "Working_Weekend con un'importanza dello 0.021387199554207138\n",
      "Traffic_Signal con un'importanza dello 0.017427909742005178\n",
      "Visibility_mi con un'importanza dello 0.012526496479246925\n",
      "Crossing con un'importanza dello 0.010704855189879325\n",
      "Astronomical_Twilight con un'importanza dello 0.009250053123785384\n",
      "Junction con un'importanza dello 0.008412287521364178\n",
      "Weather_Condition_1hot con un'importanza dello 0.0076636170031701405\n",
      "Weather_Condition_1hot con un'importanza dello 0.0072190283651356645\n",
      "Stop con un'importanza dello 0.006369056103458892\n",
      "Precipitation_in con un'importanza dello 0.00328144516967965\n",
      "Station con un'importanza dello 0.0032420743904943987\n",
      "Weather_Condition_1hot con un'importanza dello 0.0022152027175905246\n",
      "Weather_Condition_1hot con un'importanza dello 0.0020345850475773945\n",
      "Amenity con un'importanza dello 0.001728070215003171\n",
      "Railway con un'importanza dello 0.00147771576288436\n",
      "Give_Way con un'importanza dello 0.0002853715048445744\n",
      "Traffic_Calming con un'importanza dello 0.00025715402631123455\n",
      "No_Exit con un'importanza dello 0.00024262526183559523\n",
      "Bump con un'importanza dello 0.00022969177369752306\n"
     ]
    }
   ],
   "source": [
    "feat_imp=model.featureImportances\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "non_zero_elements = [(index, value) for index, value in zip(feat_imp.indices, feat_imp.values) if value != 0]\n",
    "sorted_non_zero_elements = sorted(non_zero_elements, key=lambda x: x[1], reverse=True)\n",
    "print('Le features pi importanti per la predizione sono :')\n",
    "for el in sorted_non_zero_elements:\n",
    "    if el[0]>=24:\n",
    "        print(num_col[len(num_col)-1], 'con un\\'importanza dello', el[1])\n",
    "    else:\n",
    "        print(num_col[el[0]], 'con un\\'importanza dello', el[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4d89c-fdb0-4f5d-a15c-d75a5cc3075d",
   "metadata": {},
   "source": [
    "### U_3 NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b94629-62e7-459f-82f3-3acc688b591c",
   "metadata": {},
   "source": [
    "###### data pre for Undersampling for NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ebcff849-675c-4422-bba8-a2dfaf0bf93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=trainingData_nn.groupBy('Severity').agg(F.count('Severity').alias('Count'))\n",
    "g=g.sort('Severity')\n",
    "g_p=g.toPandas()\n",
    "n_0=g_p.iloc[0,1]\n",
    "n_1=g_p.iloc[1,1]\n",
    "n_2=g_p.iloc[2,1]\n",
    "n_3=g_p.iloc[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb7c425f-6a1c-485b-a031-730f7bd154b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Severity|count|\n",
      "+--------+-----+\n",
      "|       1| 5513|\n",
      "|       3| 3285|\n",
      "|       2| 9906|\n",
      "|       0| 3352|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "und=(n_0+n_2+n_3)/3\n",
    "train_und_nn = trainingData_nn.sampleBy('Severity', fractions={0:1.0 ,1: und/n_1 , 2:1.0, 3:1.0})\n",
    "result_counts=train_und_nn.groupBy(\"Severity\").count()\n",
    "result_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f7d0bcd-8d94-4c69-9f4a-68073e05c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Layers  -> output layer must have the same number of units of the Severity classes\n",
    "layers = [len(num_col),4]\n",
    "\n",
    "# Create the Multilayer Perceptron Classifier and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(\n",
    "    layers=layers,\n",
    "    labelCol=\"Severity\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=100,  \n",
    "    tol=1e-6,\n",
    "    seed=None,\n",
    "    blockSize=32,\n",
    "    stepSize=0.03,  \n",
    "    solver=\"l-bfgs\",\n",
    "    initialWeights=None,\n",
    "    probabilityCol=\"probability\",\n",
    "    rawPredictionCol=\"rawPrediction\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = trainer.fit(train_und_nn)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions= model.transform(testData_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "406b0860-3484-4b28-8127-b895318afb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.41093016547347444\n",
      "Test Error = 0.58907\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davide\\anaconda3\\envs\\pyspark_env\\Lib\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for class  1 : 3.65%\n",
      "Recall for class  1 : 10.22%\n",
      "avg_F1-Score for class  1 : 5.38%\n",
      "----------------------------\n",
      "Precision for class  2 : 98.16%\n",
      "Recall for class  2 : 40.04%\n",
      "avg_F1-Score for class  2 : 56.88%\n",
      "----------------------------\n",
      "Precision for class  3 : 6.34%\n",
      "Recall for class  3 : 84.76%\n",
      "avg_F1-Score for class  3 : 11.81%\n",
      "----------------------------\n",
      "Precision for class  4 : 3.33%\n",
      "Recall for class  4 : 25.03%\n",
      "avg_F1-Score for class  4 : 5.88%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 19.99%\n",
      "----------------------\n",
      "[[  150.   205.   951.   162.]\n",
      " [ 3612. 42967. 50522. 10218.]\n",
      " [  205.   311.  3531.   119.]\n",
      " [  143.   290.   651.   362.]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3cc00-a288-43a4-9929-965e25d6974d",
   "metadata": {},
   "source": [
    "## C_ Over & Under \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a3e1ff6-e03f-48b4-a3e8-d50b898a79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_1=trainingData.filter(col('Severity') == 1)\n",
    "under_1 = trainingData.sample(True, 0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9be5d0f-fbe6-4c66-903a-95f73fe4f589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.058702670971527\n",
      "19.058702670971527\n",
      "18.058702670971527\n",
      "17.058702670971527\n",
      "16.058702670971527\n",
      "15.058702670971527\n",
      "14.058702670971527\n",
      "13.058702670971527\n",
      "12.058702670971527\n",
      "11.058702670971527\n",
      "10.058702670971527\n",
      "9.058702670971527\n",
      "8.058702670971527\n",
      "7.0587026709715275\n",
      "6.0587026709715275\n",
      "5.0587026709715275\n",
      "4.0587026709715275\n",
      "3.0587026709715275\n",
      "2.0587026709715275\n",
      "1.0587026709715275\n",
      "0.05870267097152748\n"
     ]
    }
   ],
   "source": [
    "#Over Sample Classe 0\n",
    "oversample_0=trainingData.filter(col('Severity') == 0)\n",
    "num_campioni_da_generare = round(n_1*0.3)\n",
    "num_campioni_da_generare=(num_campioni_da_generare-n_0)/n_0 #percentuale \n",
    "#print(num_campioni_da_generare)\n",
    "full_0=oversample_0\n",
    "#print(full.count())\n",
    "while num_campioni_da_generare>1:\n",
    "    oversample_0 = oversample_0.unionAll(full_0)\n",
    "    #trainingData_over = trainingData_over.unionAll(df_minority_oversampled)\n",
    "    num_campioni_da_generare=num_campioni_da_generare-1.0\n",
    "    #num_campioni_da_generare=num_campioni_da_generare/n_0\n",
    "    print(num_campioni_da_generare)\n",
    "    #print('------')\n",
    "    #print(trainingData_over.count())\n",
    "#print(num_campioni_da_generare, 'u')\n",
    "df_minority_oversampled = full_0.sample(True, num_campioni_da_generare, seed=42)\n",
    "\n",
    "oversample_0 = oversample_0.unionAll(df_minority_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f2a5443-2cd1-4cf8-b7d8-94708bc7216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6136156417789485\n",
      "4.6136156417789485\n",
      "3.6136156417789485\n",
      "2.6136156417789485\n",
      "1.6136156417789485\n",
      "0.6136156417789485\n"
     ]
    }
   ],
   "source": [
    "# Overs sample Classe 2\n",
    "oversample_2=trainingData.filter(col('Severity') == 2)\n",
    "num_campioni_da_generare = round(n_1*0.3)\n",
    "num_campioni_da_generare=(num_campioni_da_generare-n_2)/n_2 #percentuale \n",
    "#print(num_campioni_da_generare)\n",
    "full_2=oversample_2\n",
    "#print(full.count())\n",
    "\n",
    "while num_campioni_da_generare>1:\n",
    "    oversample_2 = oversample_2.unionAll(full_2)\n",
    "    #trainingData_over = trainingData_over.unionAll(df_minority_oversampled)\n",
    "    num_campioni_da_generare=num_campioni_da_generare-1.0\n",
    "    #num_campioni_da_generare=num_campioni_da_generare/n_0\n",
    "    print(num_campioni_da_generare)\n",
    "    #print('------')\n",
    "    #print(trainingData_over.count())\n",
    "#print(num_campioni_da_generare, 'u')\n",
    "df_minority_oversampled = full_2.sample(True, num_campioni_da_generare, seed=42)\n",
    "\n",
    "oversample_2 = oversample_2.unionAll(df_minority_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e9f7fdc-5d8c-45d6-8714-f27d7e694dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.947786259541985\n",
      "19.947786259541985\n",
      "18.947786259541985\n",
      "17.947786259541985\n",
      "16.947786259541985\n",
      "15.947786259541985\n",
      "14.947786259541985\n",
      "13.947786259541985\n",
      "12.947786259541985\n",
      "11.947786259541985\n",
      "10.947786259541985\n",
      "9.947786259541985\n",
      "8.947786259541985\n",
      "7.947786259541985\n",
      "6.947786259541985\n",
      "5.947786259541985\n",
      "4.947786259541985\n",
      "3.947786259541985\n",
      "2.947786259541985\n",
      "1.947786259541985\n",
      "0.947786259541985\n"
     ]
    }
   ],
   "source": [
    "# Oversample Classe 3 \n",
    "oversample_3=trainingData.filter(col('Severity') == 3)\n",
    "num_campioni_da_generare = round(n_1*0.3)\n",
    "num_campioni_da_generare=(num_campioni_da_generare-n_3)/n_3 #percentuale \n",
    "#print(num_campioni_da_generare)\n",
    "full_3=oversample_3\n",
    "#print(full.count())\n",
    "\n",
    "while num_campioni_da_generare>1:\n",
    "    oversample_3 = oversample_3.unionAll(full_3)\n",
    "    #trainingData_over = trainingData_over.unionAll(df_minority_oversampled)\n",
    "    num_campioni_da_generare=num_campioni_da_generare-1.0\n",
    "    #num_campioni_da_generare=num_campioni_da_generare/n_0\n",
    "    print(num_campioni_da_generare)\n",
    "    #print('------')\n",
    "    #print(trainingData_over.count())\n",
    "#print(num_campioni_da_generare, 'u')\n",
    "df_minority_oversampled = full_3.sample(True, num_campioni_da_generare, seed=42)\n",
    "\n",
    "oversample_3 = oversample_3.unionAll(df_minority_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "116f61d6-8da6-4010-a2a3-916015f060ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mezzo=oversample_0.unionAll(oversample_2).unionAll(oversample_3).unionAll(under_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ecd3c08-dd93-43ec-8fad-3d08fdec88bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305461"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mezzo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67a0c519-fbbd-423c-8ea4-b8a72760643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Severity|Count|\n",
      "+--------+-----+\n",
      "|       0|76207|\n",
      "|       1|74954|\n",
      "|       2|78069|\n",
      "|       3|76231|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "g=df_mezzo.groupBy('Severity').agg(F.count('Severity').alias('Count'))\n",
    "g=g.sort('Severity')\n",
    "g.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "251089dd-6d36-4e60-a1dc-811a72cab793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ri assegno il train \n",
    "train_mezzo=df_mezzo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026b9ff-d9e2-4259-961c-d3dfbfbdb5ba",
   "metadata": {},
   "source": [
    "### U+O A) Dt base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "239f8865-cda2-4d80-897e-f642ff29fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7703021718602455\n",
      "Test Error = 0.229698\n",
      "----------------------------\n",
      "Precision for class  1 : 36.25%\n",
      "Recall for class  1 : 71.90%\n",
      "avg_F1-Score for class  1 : 48.20%\n",
      "----------------------------\n",
      "Precision for class  2 : 99.03%\n",
      "Recall for class  2 : 77.28%\n",
      "avg_F1-Score for class  2 : 86.82%\n",
      "----------------------------\n",
      "Precision for class  3 : 37.70%\n",
      "Recall for class  3 : 75.48%\n",
      "avg_F1-Score for class  3 : 50.28%\n",
      "----------------------------\n",
      "Precision for class  4 : 5.09%\n",
      "Recall for class  4 : 67.86%\n",
      "avg_F1-Score for class  4 : 9.46%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 48.69%\n",
      "----------------------\n",
      "[[1.0160e+03 9.1000e+01 2.9900e+02 7.0000e+00]\n",
      " [1.1570e+03 8.2926e+04 4.9340e+03 1.8285e+04]\n",
      " [6.2900e+02 2.6000e+02 3.1710e+03 1.4100e+02]\n",
      " [1.0000e+00 4.5900e+02 8.0000e+00 9.8800e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\")\n",
    "\n",
    "dt = dt.fit(train_mezzo)\n",
    "predictions = dt.transform(testData)\n",
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c29a262e-a756-4086-bfcd-3f1b43bc9791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.1816, 1: 0.0361, 2: 0.5254, 6: 0.0006, 10: 0.0009, 12: 0.001, 19: 0.0167, 20: 0.1706, 21: 0.0032, 22: 0.0537, 23: 0.0101})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4513e-d871-4bd0-8aa0-cd1be87ca5a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### U+O_A)_a) DT Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cccf7074-451b-42d6-a4db-2488176c2a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8538278599657259\n",
      "Test Error = 0.146172\n",
      "----------------------------\n",
      "Precision for class  1 : 27.25%\n",
      "Recall for class  1 : 64.61%\n",
      "avg_F1-Score for class  1 : 38.34%\n",
      "----------------------------\n",
      "Precision for class  2 : 98.33%\n",
      "Recall for class  2 : 86.58%\n",
      "avg_F1-Score for class  2 : 92.08%\n",
      "----------------------------\n",
      "Precision for class  3 : 38.43%\n",
      "Recall for class  3 : 71.58%\n",
      "avg_F1-Score for class  3 : 50.01%\n",
      "----------------------------\n",
      "Precision for class  4 : 9.56%\n",
      "Recall for class  4 : 57.28%\n",
      "avg_F1-Score for class  4 : 16.39%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 49.20%\n",
      "----------------------\n",
      "[[9.130e+02 2.180e+02 2.750e+02 7.000e+00]\n",
      " [2.036e+03 9.290e+04 4.519e+03 7.847e+03]\n",
      " [3.920e+02 7.660e+02 3.007e+03 3.600e+01]\n",
      " [9.000e+00 5.890e+02 2.400e+01 8.340e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "\n",
    "dt_param1 = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\",\n",
    "                                  maxDepth=20,\n",
    "                                  maxBins=32)\n",
    "                                   \n",
    "\n",
    "dt_param1 = dt_param1.fit(train_mezzo)\n",
    "predictions_param1 = dt_param1.transform(testData)\n",
    "print_metrics_and_cf(predictions_param1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d63a5585-8466-4f13-8d64-75c7e15cd848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.1816, 1: 0.0361, 2: 0.5254, 6: 0.0006, 10: 0.0009, 12: 0.001, 19: 0.0167, 20: 0.1706, 21: 0.0032, 22: 0.0537, 23: 0.0101})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c40466-48c3-422a-8830-abda1e9d24f6",
   "metadata": {},
   "source": [
    "### U+O_A)_b) DT Tuning Pesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba4b6963-4b69-48a6-93b6-c1707a8a5cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Severity|Count|\n",
      "+--------+-----+\n",
      "|       1|74954|\n",
      "|       3|76001|\n",
      "|       0|77478|\n",
      "|       2|77778|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "g=train_mezzo.groupBy('Severity').agg(F.count('Severity').alias('Count'))\n",
    "g.sort('Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c512d329-7bff-4e5d-9879-1661743262f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIRE I PESI !!!!!!!!  <-------------------------------------------------------------------------------\n",
    "trainingData_w = train_mezzo.withColumn(\"weights2\", when(trainingData[\"Severity\"] == 1, 1.0)\n",
    "    .when(trainingData[\"Severity\"] == 0, 306211 / 77478)  # Calcolo del peso per la classe 1\n",
    "    .when(trainingData[\"Severity\"] == 2, 306211 / 77778)  # Calcolo del peso per la classe 3\n",
    "    .when(trainingData[\"Severity\"] == 3, 306211 / 76001)  # Calcolo del peso per la classe 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "623c02cd-6b46-4102-af3e-6bdf2adee473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8891599342496416\n",
      "Test Error = 0.11084\n",
      "----------------------------\n",
      "Precision for class  1 : 32.18%\n",
      "Recall for class  1 : 57.89%\n",
      "avg_F1-Score for class  1 : 41.37%\n",
      "----------------------------\n",
      "Precision for class  2 : 97.94%\n",
      "Recall for class  2 : 90.75%\n",
      "avg_F1-Score for class  2 : 94.21%\n",
      "----------------------------\n",
      "Precision for class  3 : 39.06%\n",
      "Recall for class  3 : 65.60%\n",
      "avg_F1-Score for class  3 : 48.97%\n",
      "----------------------------\n",
      "Precision for class  4 : 13.98%\n",
      "Recall for class  4 : 51.37%\n",
      "avg_F1-Score for class  4 : 21.97%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 51.63%\n",
      "----------------------\n",
      "[[8.1800e+02 2.7400e+02 3.1200e+02 9.0000e+00]\n",
      " [1.3970e+03 9.7373e+04 3.9620e+03 4.5700e+03]\n",
      " [3.2300e+02 1.0970e+03 2.7560e+03 2.5000e+01]\n",
      " [4.0000e+00 6.7800e+02 2.6000e+01 7.4800e+02]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "\n",
    "dt_param2 = DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\",\n",
    "                                  maxDepth=30,\n",
    "                                  maxBins=32,\n",
    "                                weightCol='weights2'  \n",
    "                                  )\n",
    "                                   \n",
    "\n",
    "dt_param2 = dt_param2.fit(trainingData_w)\n",
    "predictions_param2 = dt_param2.transform(testData)\n",
    "print_metrics_and_cf(predictions_param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28c82a01-e5e7-44a1-9d18-01e472dbe43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.1816, 1: 0.0361, 2: 0.5254, 6: 0.0006, 10: 0.0009, 12: 0.001, 19: 0.0167, 20: 0.1706, 21: 0.0032, 22: 0.0537, 23: 0.0101})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81ff5e-6dae-463c-b9f5-a59863303e12",
   "metadata": {},
   "source": [
    "### U+O B_ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcec823d-06cd-4cd3-b12b-4c68f84d7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"Severity\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = rf.fit(train_mezzo)\n",
    "\n",
    "# Make predictions.\n",
    "\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35e7a5ba-6ac1-4afc-b125-2f3b9c742994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6475011366418354\n",
      "Test Error = 0.352499\n",
      "----------------------------\n",
      "Precision for class  1 : 37.13%\n",
      "Recall for class  1 : 72.68%\n",
      "avg_F1-Score for class  1 : 49.15%\n",
      "----------------------------\n",
      "Precision for class  2 : 99.09%\n",
      "Recall for class  2 : 64.04%\n",
      "avg_F1-Score for class  2 : 77.80%\n",
      "----------------------------\n",
      "Precision for class  3 : 37.86%\n",
      "Recall for class  3 : 76.12%\n",
      "avg_F1-Score for class  3 : 50.57%\n",
      "----------------------------\n",
      "Precision for class  4 : 3.31%\n",
      "Recall for class  4 : 76.85%\n",
      "avg_F1-Score for class  4 : 6.35%\n",
      "----------------------------\n",
      "----------------------\n",
      "avg_F1-Score: 45.96%\n",
      "----------------------\n",
      "[[1.0270e+03 5.5000e+01 2.8800e+02 4.3000e+01]\n",
      " [1.1370e+03 6.8712e+04 4.9540e+03 3.2499e+04]\n",
      " [6.0100e+02 2.4900e+02 3.1980e+03 1.5300e+02]\n",
      " [1.0000e+00 3.2800e+02 8.0000e+00 1.1190e+03]]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf9ada98-d805-420a-b6dd-c69682382b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28, {0: 0.1611, 1: 0.0984, 2: 0.4172, 3: 0.0424, 4: 0.0069, 5: 0.0001, 6: 0.0064, 7: 0.0001, 8: 0.0002, 9: 0.0, 10: 0.0066, 12: 0.0, 16: 0.0001, 17: 0.0045, 18: 0.0, 19: 0.0094, 20: 0.1724, 21: 0.0291, 22: 0.0406, 23: 0.0018, 24: 0.0003, 25: 0.0001, 26: 0.002})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "513fef06-3230-4713-8158-a97f6608f3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le features pi importanti per la predizione sono :\n",
      "Distance_mi con un'importanza dello 0.4172273529766177\n",
      "month con un'importanza dello 0.17235023803006808\n",
      "Start_Lat con un'importanza dello 0.16113531962603805\n",
      "Start_Lng con un'importanza dello 0.09843555704989608\n",
      "Temperature_F con un'importanza dello 0.04242030342157565\n",
      "Working_Weekend con un'importanza dello 0.04061534859422437\n",
      "hour con un'importanza dello 0.029109616161463847\n",
      "Traffic_Signal con un'importanza dello 0.009440405853263379\n",
      "Humidity_perc con un'importanza dello 0.00692223141406977\n",
      "Crossing con un'importanza dello 0.006624621042602222\n",
      "Wind_Speed_mph con un'importanza dello 0.006417921782229011\n",
      "Stop con un'importanza dello 0.004469155898827137\n",
      "Weather_Condition_1hot con un'importanza dello 0.0019704588283467528\n",
      "Astronomical_Twilight con un'importanza dello 0.0018463797212776491\n",
      "Weather_Condition_1hot con un'importanza dello 0.0002640871170730634\n",
      "Amenity con un'importanza dello 0.00020590118375243583\n",
      "Visibility_mi con un'importanza dello 0.0001454563972680344\n",
      "Weather_Condition_1hot con un'importanza dello 0.00012744932095367137\n",
      "Precipitation_in con un'importanza dello 0.00011820534423800785\n",
      "Station con un'importanza dello 6.87356614617483e-05\n",
      "Bump con un'importanza dello 4.8902093284292644e-05\n",
      "Junction con un'importanza dello 1.846901829878032e-05\n",
      "Traffic_Calming con un'importanza dello 1.7883463170340624e-05\n"
     ]
    }
   ],
   "source": [
    "feat_imp=model.featureImportances\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "non_zero_elements = [(index, value) for index, value in zip(feat_imp.indices, feat_imp.values) if value != 0]\n",
    "sorted_non_zero_elements = sorted(non_zero_elements, key=lambda x: x[1], reverse=True)\n",
    "print('Le features pi importanti per la predizione sono :')\n",
    "for el in sorted_non_zero_elements:\n",
    "    if el[0]>=24:\n",
    "        print(num_col[len(num_col)-1], 'con un\\'importanza dello', el[1])\n",
    "    else:\n",
    "        print(num_col[el[0]], 'con un\\'importanza dello', el[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b0c10-22ac-4fa4-bfbd-f9620ad0f32d",
   "metadata": {},
   "source": [
    "### U+O C_ NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4deb770-5be8-484d-b39b-8e060adba285",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_1_nn=trainingData_nn.filter(col('Severity') == 1)\n",
    "under_1_nn = trainingData_nn.sample(True, 0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7cab86e5-8498-476e-9a4b-efd8b94b9fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.418854415274463\n",
      "19.418854415274463\n",
      "18.418854415274463\n",
      "17.418854415274463\n",
      "16.418854415274463\n",
      "15.418854415274463\n",
      "14.418854415274463\n",
      "13.418854415274463\n",
      "12.418854415274463\n",
      "11.418854415274463\n",
      "10.418854415274463\n",
      "9.418854415274463\n",
      "8.418854415274463\n",
      "7.418854415274463\n",
      "6.418854415274463\n",
      "5.418854415274463\n",
      "4.418854415274463\n",
      "3.4188544152744633\n",
      "2.4188544152744633\n",
      "1.4188544152744633\n",
      "0.4188544152744633\n"
     ]
    }
   ],
   "source": [
    "oversample_0_nn=trainingData_nn.filter(col('Severity') == 0)\n",
    "num_campioni_da_generare = round(n_1*0.3)\n",
    "num_campioni_da_generare=(num_campioni_da_generare-n_0)/n_0 \n",
    "full_0_nn=oversample_0_nn\n",
    "\n",
    "while num_campioni_da_generare>1:\n",
    "    oversample_0_nn = oversample_0_nn.unionAll(full_0_nn)\n",
    "    num_campioni_da_generare=num_campioni_da_generare-1.0\n",
    "    print(num_campioni_da_generare)\n",
    "    \n",
    "df_minority_oversampled_nn = full_0_nn.sample(True, num_campioni_da_generare, seed=42)\n",
    "\n",
    "oversample_0_nn = oversample_0_nn.unionAll(df_minority_oversampled_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa8c21cb-503f-4181-95d3-0a8aef4d271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.586109428629114\n",
      "4.586109428629114\n",
      "3.586109428629114\n",
      "2.586109428629114\n",
      "1.586109428629114\n",
      "0.586109428629114\n"
     ]
    }
   ],
   "source": [
    "oversample_2_nn=trainingData_nn.filter(col('Severity') == 2)\n",
    "num_campioni_da_generare = round(n_1*0.3)\n",
    "num_campioni_da_generare=(num_campioni_da_generare-n_2)/n_2\n",
    "full_2_nn=oversample_2_nn\n",
    "\n",
    "while num_campioni_da_generare>1:\n",
    "    oversample_2_nn = oversample_2_nn.unionAll(full_2_nn)\n",
    "    num_campioni_da_generare=num_campioni_da_generare-1.0\n",
    "    print(num_campioni_da_generare)\n",
    "    \n",
    "df_minority_oversampled_nn = full_2_nn.sample(True, num_campioni_da_generare, seed=42)\n",
    "\n",
    "oversample_2_nn = oversample_2_nn.unionAll(df_minority_oversampled_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8260d82b-9805-45c3-a214-108a16c27557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.876103500761037\n",
      "19.876103500761037\n",
      "18.876103500761037\n",
      "17.876103500761037\n",
      "16.876103500761037\n",
      "15.876103500761037\n",
      "14.876103500761037\n",
      "13.876103500761037\n",
      "12.876103500761037\n",
      "11.876103500761037\n",
      "10.876103500761037\n",
      "9.876103500761037\n",
      "8.876103500761037\n",
      "7.876103500761037\n",
      "6.876103500761037\n",
      "5.876103500761037\n",
      "4.876103500761037\n",
      "3.8761035007610367\n",
      "2.8761035007610367\n",
      "1.8761035007610367\n",
      "0.8761035007610367\n"
     ]
    }
   ],
   "source": [
    "oversample_3_nn=trainingData_nn.filter(col('Severity') == 3)\n",
    "num_campioni_da_generare = round(n_1*0.3)\n",
    "num_campioni_da_generare=(num_campioni_da_generare-n_3)/n_3  \n",
    "full_3_nn=oversample_3_nn\n",
    "\n",
    "while num_campioni_da_generare>1:\n",
    "    oversample_3_nn = oversample_3_nn.unionAll(full_3_nn)\n",
    "    num_campioni_da_generare=num_campioni_da_generare-1.0\n",
    "    print(num_campioni_da_generare)\n",
    "    \n",
    "df_minority_oversampled_nn = oversample_3_nn.sample(True, num_campioni_da_generare, seed=42)\n",
    "\n",
    "oversample_3_nn = oversample_3_nn.unionAll(df_minority_oversampled_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "745e5094-601d-4ca9-a040-7c64704e8221",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 5) (3786177059.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[89], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f'Class 0: {class0_counts}\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 5)\n"
     ]
    }
   ],
   "source": [
    "class0_counts=oversample_0_nn.count()\n",
    "class2_counts=oversample_2_nn.count()\n",
    "class3_counts=oversample_3_nn.count()\n",
    "class1_counts=under_1_nn.count()\n",
    "print(f'Class 0: {class0_counts}\n",
    "Class 1: {class1_counts}\n",
    "Class 2: {class2_counts}\n",
    "Class 3: {class3_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d633783-cdeb-4ec5-85b5-903ec9ec366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_und_over_nn=oversample_0_nn.unionAll(oversample_2_nn).unionAll(oversample_3_nn).unionAll(under_1_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23c213-4df7-4e31-a7c6-b34eda7c538b",
   "metadata": {},
   "source": [
    "#### U+O C_ a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdced9e-d31f-4fc5-8395-50dca204dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Layers  -> output layer must have the same number of units of the Severity classes\n",
    "layers = [len(num_col),16,32,16,8,4]\n",
    "\n",
    "# Create the Multilayer Perceptron Classifier and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(\n",
    "    layers=layers,\n",
    "    blockSize=128,\n",
    "    labelCol=\"Severity\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=100\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = trainer.fit(train_und_over_nn)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions= model.transform(testData_nn)\n",
    "\n",
    "print_metrics_and_cf(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab05dc-f2b5-49b0-aec3-0958e820ff24",
   "metadata": {},
   "source": [
    "#### U+0 C_ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1e207-84bd-4a72-895c-121710849b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [len(num_col),4]\n",
    "\n",
    "# Create the Multilayer Perceptron Classifier and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(\n",
    "    layers=layers,\n",
    "    labelCol=\"Severity\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=100,  \n",
    "    tol=1e-6,\n",
    "    seed=None,\n",
    "    blockSize=32,\n",
    "    stepSize=0.03,  \n",
    "    solver=\"l-bfgs\",\n",
    "    initialWeights=None,\n",
    "    probabilityCol=\"probability\",\n",
    "    rawPredictionCol=\"rawPrediction\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = trainer.fit(train_und_over)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions= model.transform(testData)\n",
    "\n",
    "print_metrics_and_cf(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
